{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "(x_train_orig, y_train_orig), (x_test_orig, y_test_orig) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1)\n",
      "(10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_orig.shape, y_train_orig.shape)\n",
    "print(x_test_orig.shape, y_test_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(targets, nb_classes):\n",
    "    res = np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
    "#     return res.reshape(list(targets.shape)+[nb_classes])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_orig[:10000,] / 255\n",
    "y_train = get_one_hot(y_train_orig[:10000,:], 10)\n",
    "y_test = y_test_orig / 255\n",
    "y_test = get_one_hot(y_test_orig, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_place_holder(n_H, n_W, n_C, n_y):\n",
    "    X = tf.placeholder(tf.float32, shape=(None, n_H, n_W, n_C), name=\"X\")\n",
    "    y = tf.placeholder(tf.float32, shape=(None, n_y), name=\"y\")\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_param():\n",
    "#     [filter_height, filter_width, in_channels, out_channels]\n",
    "    \n",
    "    W1= tf.get_variable(shape=(5,5,3,8), initializer=tf.contrib.layers.xavier_initializer(), name=\"W1\")\n",
    "    W2= tf.get_variable(shape=(7,7,8,16), initializer=tf.contrib.layers.xavier_initializer(), name=\"W2\")\n",
    "    \n",
    "    param = {\n",
    "        \"W1\" : W1,\n",
    "        \"W2\" : W2\n",
    "    }\n",
    "    \n",
    "    return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, param):\n",
    "    \"\"\"\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \"\"\"\n",
    "    W1 = param[\"W1\"]\n",
    "    W2 = param[\"W2\"]\n",
    "    \n",
    "    Z1 = tf.nn.conv2d(input=X, filter=W1, strides=(1,1,1,1), padding=\"SAME\", name=\"conv1\")\n",
    "    A1 = tf.nn.relu(Z1, name=\"relu1\")\n",
    "    P1 = tf.nn.max_pool(A1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"VALID\", name=\"maxpool1\")\n",
    "    \n",
    "    Z2 = tf.nn.conv2d(input=P1, filter=W2, strides=(1,1,1,1), padding=\"SAME\", name=\"conv2\")\n",
    "    A2 = tf.nn.relu(Z2, name=\"relu2\")\n",
    "    P2 = tf.nn.max_pool(A2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"VALID\", name=\"maxpool2\")\n",
    "    \n",
    "    F1 = tf.layers.flatten(P2)\n",
    "    Z3 = tf.contrib.layers.fully_connected(inputs=F1, num_outputs=10, activation_fn=None)\n",
    "    \n",
    "    cache = {\n",
    "        \"Z1\" : Z1,\n",
    "        \"Z2\" : Z2,\n",
    "        \"Z3\" : Z3,\n",
    "        \"A1\" : A1,\n",
    "        \"A2\" : A2,\n",
    "        \"P1\" : P1,\n",
    "        \"P2\" : P2,\n",
    "        \"F1\" : F1\n",
    "    }\n",
    "    \n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z3, y):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z3, labels=y))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, y_train, learning_rate = 0.0001, num_epochs=100):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    (m, n_H, n_W, n_C) = X_train.shape\n",
    "    (m, n_y) = y_train.shape\n",
    "    \n",
    "    X, y = creat_place_holder(n_H, n_W, n_C, n_y)\n",
    "    param = init_param()\n",
    "    cache = forward_propagation(X, param)\n",
    "    \n",
    "    Z3 = cache[\"Z3\"]\n",
    "    \n",
    "    cost = compute_cost(Z3, y)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "     \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init)\n",
    "        \n",
    "        costs = []\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            cost_epoch, _ = sess.run([cost, optimizer], feed_dict={X:X_train, y:y_train})\n",
    "            \n",
    "            if(epoch%5 == 0):\n",
    "                costs.append(cost_epoch)\n",
    "                print(epoch, cost_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b5832115483b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
